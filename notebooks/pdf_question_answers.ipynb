{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - Answering with PDF\n",
    "\n",
    "- Document Loaders\n",
    "- Chat Models\n",
    "- Embeddings\n",
    "- Vector Stores\n",
    "- Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../data/big-book-of-machine-learning-use-cases-2nd-edition.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Book of Machine \n",
      "Learning Use Cases\n",
      "A collection of technical \n",
      "blogs, including code \n",
      "samples an\n",
      "{'source': '../data/big-book-of-machine-learning-use-cases-2nd-edition.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dazzpool/Documents/Github/docuChatAI/venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/var/folders/kc/_ltsfdfs0c52y7zx5573skr40000gn/T/ipykernel_13746/2844637147.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
      "/Users/dazzpool/Documents/Github/docuChatAI/venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/dazzpool/Documents/Github/docuChatAI/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the projects I should work on?',\n",
       " 'context': [Document(metadata={'page': 75, 'source': '../data/big-book-of-machine-learning-use-cases-2nd-edition.pdf'}, page_content='Notebook , and RasterFrames Notebook . Also, stay tuned for a new section in our \\ndocumentation specifically for geospatial topics of interest.\\n76\\nEBOOK: BIG BOOK OF MACHINE LEARNING USE CASES — 2ND EDITION'),\n",
       "  Document(metadata={'page': 62, 'source': '../data/big-book-of-machine-learning-use-cases-2nd-edition.pdf'}, page_content='DEFENSE AND INTEL\\nReconnaissance, threat \\ndetection, damage assessmentFINANCIAL SERVICES\\nEconomic distribution, loan risk \\nanalysis, predicting sales at \\nretail, investments\\nINFRASTRUCTURE\\nTransportation planning, \\nagriculture management, \\nhousing developmentHEALTHCARE\\nIdentifying disease epicenters, \\nenvironmental impact on \\nhealth, planning care\\nENERGY\\nClimate change analysis, energy \\nasset inspection, oil discovery\\nMaps leveraging geospatial data  \\nare used widely across industries,  \\nspanning multiple use cases, including \\ndisaster recovery, defense and intel, \\ninfrastructure and health services.63\\nEBOOK: BIG BOOK OF MACHINE LEARNING USE CASES — 2ND EDITION'),\n",
       "  Document(metadata={'page': 84, 'source': '../data/big-book-of-machine-learning-use-cases-2nd-edition.pdf'}, page_content='to completing this project efficiently. In a short period of time, the team was able \\nto build the data pipeline, complete machine learning models and produce high-\\nquality visualizations to communicate results. The infrastructure provided by the \\nDatabricks platform removed many of the technical challenges and enabled the \\nproject to be successful.\\nWhile this tool will not enable you to outwit the cryptocurrency markets, we \\nstrongly believe it will predict periods of increased volatility, which can be \\nadvantageous for specific investing conditions.\\nDisclaimer: This article takes no responsibility for financial investment decisions. \\nNothing contained in this website should be construed as investment advice.\\n \\nTry notebooks\\nPlease try out the referenced Databricks notebooks\\nData Science \\n     Merge to Gold \\nOrchestrator \\n     Inference \\nTweepy \\n     Y _ F i n a n c e  \\n85\\nEBOOK: BIG BOOK OF MACHINE LEARNING USE CASES — 2ND EDITION'),\n",
       "  Document(metadata={'page': 88, 'source': '../data/big-book-of-machine-learning-use-cases-2nd-edition.pdf'}, page_content='quickly get in and utilize large volumes of data to \\nmake actionable business decisions.”\\n —  Paul Fryzel  \\nPrincipal Engineer of AI Infrastructure \\nCondé NastLearn more\\n89\\nEBOOK: BIG BOOK OF MACHINE LEARNING USE CASES — 2ND EDITION')],\n",
       " 'answer': 'Based on the provided context, you might consider working on projects in the following areas:\\n\\n1. **Defense and Intel**: Reconnaissance, threat detection, and damage assessment.\\n2. **Financial Services**: Economic distribution, loan risk analysis, predicting sales at retail, and investments.\\n3. **Infrastructure**: Transportation planning, agriculture management, and housing development.\\n4. **Healthcare**: Identifying disease epicenters, environmental impact on health, and planning care.\\n5. **Energy**: Climate change analysis, energy asset inspection, and oil discovery.\\n\\nThese areas leverage geospatial data and machine learning, which are widely applicable across various industries.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"What are the projects I should work on?\"})\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
